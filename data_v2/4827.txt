thumb 400px an illustration of lightbulb problem where one is searching for a broken bulb among six lightbulbs here first three are connected to a power supply and they light up a this indicates that broken bulb must be one of last three b if instead bulbs did not light up one could be sure that broken bulb was among first three continuing this procedure can locate broken bulb in no more than three tests compared to a maximum of six tests if bulbs are checked individually in statistics and combinatorial mathematics group testing is any procedure that breaks up task of identifying certain objects into tests on groups of items rather than on individual ones first studied by robert dorfman in 1943 group testing is a relatively new field of applied mathematics that can be applied to a wide range of practical applications and is an active area of research today a familiar example of group testing involves a string of light bulbs connected in series where exactly one of bulbs is known to be broken objective is to find broken bulb using smallest number of tests where a test is when some of bulbs are connected to a power supply a simple approach is to test each bulb individually however when there are a large number of bulbs it would be much more efficient to pool bulbs into groups for example by connecting first half of bulbs at once it can be determined which half broken bulb is in ruling out half of bulbs in just one test schemes for carrying out group testing can be simple or complex and tests involved at each stage may be different schemes in which tests for next stage depend on results of previous stages are called adaptive procedures while schemes designed so that all tests are known beforehand are called non adaptive procedures structure of scheme of tests involved in a non adaptive procedure is known as a pooling design group testing has many applications including statistics biology computer science medicine engineering and cyber security modern interest in these testing schemes has been rekindled by human genome project basic description and terms unlike many areas of mathematics origins of group testing can be traced back to a single report written by a single person robert dorfman motivation arose during second world war when united states public health service and selective service embarked upon a large scale project to weed out all syphilitic men called up for induction testing an individual for syphilis involves drawing a blood sample from them and then analysing sample to determine presence or absence of syphilis at time performing this test was expensive and testing every soldier individually would have been very expensive and inefficient supposing there are soldiers this method of testing leads to separate tests if a large proportion of people are infected then this method would be reasonable however in more likely case that only a very small proportion of men are infected a much more efficient testing scheme can be achieved feasibility of a more effective testing scheme hinges on following property soldiers can be pooled into groups and in each group blood samples can be combined together combined sample can then be tested to check if at least one soldier in group has syphilis this is central idea behind group testing if one or more of soldiers in this group has syphilis then a test is wasted more tests need to be performed to find which soldier s it was on other hand if no one in pool has syphilis then many tests are saved since every soldier in that group can be eliminated with just one test items that cause a group to test positive are generally called defective items these are broken lightbulbs syphilitic men etc often total number of items is denoted as and represents number of defectives if it is assumed to be known classification of group testing problems there are two independent classifications for group testing problems every group testing problem is either adaptive or non adaptive and either probabilistic or combinatorial in probabilistic models defective items are assumed to follow some probability distribution and aim is to minimise expected number of tests needed to identify defectiveness of every item on other hand with combinatorial group testing goal is to minimise number of tests needed in a worst case scenario that is create a minmax algorithm and no knowledge of distribution of defectives is assumed other classification adaptivity concerns what information can be used when choosing which items to group into a test in general choice of which items to test can depend on results of previous tests as in above lightbulb problem an algorithm that proceeds by performing a test and then using result and all past results to decide which next test to perform is called adaptive conversely in non adaptive algorithms all tests are decided in advance this idea can be generalised to multistage algorithms where tests are divided into stages and every test in next stage must be decided in advance with only knowledge of results of tests in previous stages although adaptive algorithms offer much more freedom in design it is known that adaptive group testing algorithms do not improve upon non adaptive ones by more than a constant factor in number of tests required to identify set of defective items in addition to this non adaptive methods are often useful in practice because one can proceed with successive tests without first analysing results of all previous tests allowing for effective distribution of testing process variations and extensions there are many ways to extend problem of group testing one of most important is called noisy group testing and deals with a big assumption of original problem that testing is error free a group testing problem is called noisy when there is some chance that result of a group test is erroneous e g comes out positive when test contained no defectives bernoulli noise model assumes this probability is some constant but in general it can depend on true number of defectives in test and number of items tested for example effect of dilution can be modelled by saying a positive result is more likely when there are more defectives or more defectives as a fraction of number tested present in test a noisy algorithm will always have a non zero probability of making an error that is mislabeling an item group testing can be extended by considering scenarios in which there are more than two possible outcomes of a test for example a test may have outcomes and corresponding to there being no defectives a single defective or an unknown number of defectives larger than one more generally it is possible to consider outcome set of a test to be for some another extension is to consider geometric restrictions on which sets can be tested above lightbulb problem is an example of this kind of restriction only bulbs that appear consecutively can be tested similarly items may be arranged in a circle or in general a net where tests are available paths on graph another kind of geometric restriction would be on maximum number of items that can be tested in a group or group sizes might have to be even and so on in a similar way it may be useful to consider restriction that any given item can only appear in a certain number of tests there are endless ways to continue remixing basic formula of group testing following elaborations will give an idea of some of more exotic variants in good mediocre bad model each item is one of good mediocre or bad and result of a test is type of worst item in group in threshold group testing result of a test is positive if number of defective items in group is greater than some threshold value or proportion group testing with inhibitors is a variant with applications in molecular biology here there is a third class of items called inhibitors and result of a test is positive if it contains at least one defective and no inhibitors history and development invention and initial progress concept of group testing was first introduced by robert dorfman in 1943 in a short report published in notes section of annals of mathematical statistics dorfman s report as with all early work on group testing focused on probabilistic problem and aimed to use novel idea of group testing to reduce expected number of tests needed to weed out all syphilitic men in a given pool of soldiers method was simple put soldiers into groups of a given size and use individual testing testing items in groups of size one on positive groups to find which were infected dorfman tabulated optimum group sizes for this strategy against prevalence rate of defectiveness in population after 1943 group testing remained largely untouched for a number of years then in 1957 sterrett produced an improvement on dorfman s procedure this newer process starts by again performing individual testing on positive groups but stopping as soon as a defective is identified then remaining items in group are tested together since it is very likely that none of them are defective first thorough treatment of group testing was given by sobel and in their formative 1959 paper on subject they described five new procedures in addition to generalisations for when prevalence rate is unknown and for most optimal one they provided an explicit formula for expected number of tests it would use paper also made connection between group testing and information theory for first time as well as discussing several generalisations of group testing problem and providing some new applications of theory combinatorial group testing group testing was first studied in combinatorial context by li in 1962 with introduction of li s stage algorithm li proposed an extension of dorfman s 2 stage algorithm to an arbitrary number of stages that required no more than tests to be guaranteed to find or fewer defectives among items idea was to remove all items in negative tests and divide remaining items into groups as was done with initial pool this was to be done times before performing individual testing combinatorial group testing in general was later studied more fully by katona in 1973 katona introduced matrix representation of non adaptive group testing and produced a procedure for finding defective in non adaptive 1 defective case in no more than tests which he also proved to be optimal in general finding optimal algorithms for adaptive combinatorial group testing is difficult and although computational complexity of group testing has not been determined it is suspected to be hard in some complexity class however an important breakthrough occurred in 1972 with introduction of generalised binary splitting algorithm generalised binary splitting algorithm works by performing a binary search on groups that test positive and is a simple algorithm that finds a single defective in no more than information lower bound number of tests in scenarios where there are two or more defectives generalised binary splitting algorithm still produces near optimal results requiring at most tests above information lower bound where is number of defectives considerable improvements to this were made in 2013 by allemann getting required number of tests to less than above information lower bound when and this was achieved by changing binary search in binary splitting algorithm to a complex set of sub algorithms with overlapping test groups as such problem of adaptive combinatorial group testing with a known number or upper bound on number of defectives has essentially been solved with little room for further improvement there is an open question as to when individual testing is minmax hu hwang and wang showed in 1981 that individual testing is minmax when and that it is not minmax when it is currently conjectured that this bound is sharp that is individual testing is minmax if and only if some progress was made in 2000 by and colbourn who showed that for large individual testing is minmax when non adaptive and probabilistic testing one of key insights in non adaptive group testing is that significant gains can be made by eliminating requirement that group testing procedure be certain to succeed combinatorial problem but rather permit it to have some low but non zero probability of mis labelling each item probabilistic problem it is known that as number of defective items approaches total number of items exact combinatorial solutions require significantly more tests than probabilistic solutions even probabilistic solutions permitting only an asymptotically small probability of error in this vein chan et al 2011 introduced comp a probabilistic algorithm that requires no more than tests to find up to defectives in items with a probability of error no more than this is within a constant factor of lower bound chan et al 2011 also provided a generalisation of comp to a simple noisy model and similarly produced an explicit performance bound which was again only a constant dependent on likelihood of a failed test above corresponding lower bound in general number of tests required in bernoulli noise case is a constant factor larger than in noiseless case aldridge and johnson 2014 produced an extension of comp algorithm that added additional post processing steps they showed that performance of this new algorithm called dd strictly exceeds that of comp and that dd is essentially optimal in scenarios where by comparing it to a hypothetical algorithm that defines a reasonable optimum performance of this hypothetical algorithm suggests that there is room for improvement when as well as suggesting how much improvement this might be formalisation of combinatorial group testing this section formally defines notions and terms relating to group testing input vector is defined to be a binary vector of length that is with j th item being called defective if and only if further any non defective item is referred called a good item is intended to describe unknown set of defective items key property of is that it is an implicit input that is to say there is no direct knowledge of what entries of are other than that which can be inferred via some series of tests this leads on to next definition let be an input vector a set is called a test when testing is noiseless result of a test is positive when there exists such that and result is negative otherwise therefore goal of group testing is to come up with a method for choosing a short series of tests that allow to be determined either exactly or with a high degree of certainty a group testing algorithm is said to make an error if it incorrectly labels an item that is labels any defective item as non defective or vice versa this is not same thing as result of a group test being incorrect an algorithm is called zero error if probability that it makes an error is zero denotes minimum number of tests required to always find defectives among items with zero probability of error by any group testing algorithm for same quantity but with restriction that algorithm is non adaptive notation is used general bounds since it is always possible to resort to individual testing by setting for each it must be that that also since any non adaptive testing procedure can be written as an adaptive algorithm by simply performing all tests without regard to their outcome finally when there is at least one item whose defectiveness must be determined by at least one test and so in summary when assuming information lower bound a lower bound on number of tests needed can be described using notion of sample space denoted which is simply set of possible placements of defectives for any group testing problem with sample space and any group testing algorithm it can be shown that where is minimum number of tests required to identify all defectives with a zero probability of error this is called information lower bound this bound is derived from fact that after each test is split into two disjoint subsets each corresponding to one of two possible outcomes of test however information lower bound itself is usually unachievable even for small problems this is because splitting of is not arbitrary since it must be realisable by some test in fact information lower bound can be generalised to case where there is a non zero probability that algorithm makes an error in this form theorem gives us an upper bound on probability of success based on number of tests for any group testing algorithm that performs tests probability of success satisfies this can be strengthened to representation of non adaptive algorithms 400px thumb a typical group testing setup a non adaptive algorithm first chooses matrix and is then given vector y problem is then to find an estimate for x alt a diagram showing a group testing matrix along with associated vectors x and y algorithms for non adaptive group testing consist of two distinct phases first it is decided how many tests to perform and which items to include in each test in second phase often called decoding step results of each group test are analysed to determine which items are likely to be defective first phase is usually encoded in a matrix as follows suppose a non adaptive group testing procedure for items consists of tests for some testing matrix for this scheme is binary matrix where if and only if and is zero otherwise thus each column of represents an item and each row represents a test with a in entry indicating that test included item and a indicating otherwise as well as vector of length that describes unknown defective set it is common to introduce result vector which describes results of each test let be number of tests performed by a non adaptive algorithm result vector is a binary vector of length that is such that if and only if result of test was positive i e contained at least one defective with these definitions non adaptive problem can be reframed as follows first a testing matrix is chosen after which vector is returned then problem is to analyse to find some estimate for in simplest noisy case where there is a constant probability that a group test will have an erroneous result one considers a random binary vector where each entry has a probability of being and is otherwise vector that is returned is then with usual addition on equivalently this is element wise xor operation a noisy algorithm must estimate using that is without direct knowledge of bounds for non adaptive algorithms matrix representation makes it possible to prove some bounds on non adaptive group testing approach mirrors that of many deterministic designs where separable matrices are considered as defined below a binary matrix is called separable if every boolean sum logical or of any of its columns is distinct additionally notation separable indicates that every sum of any of up to of s columns is distinct this is not same as being separable for every when is a testing matrix property of being separable separable is equivalent to being able to distinguish between up to defectives however it does not guarantee that this will be straightforward a stronger property called does a binary matrix is called disjunct if boolean sum of any columns does not contain any other column in this context a column a is said to contain a column b if for every index where b has a 1 a also has a 1 a useful property of disjunct testing matrices is that with up to defectives every non defective item will appear in at least one test whose outcome is negative this means there is a simple procedure for finding defectives just remove every item that appears in a negative test using properties of separable and disjunct matrices following can be shown for problem of identifying defectives among total items number of tests needed for an asymptotically small average probability of error scales as number of tests needed for an asymptotically small maximum probability of error scales as number of tests needed for a zero probability of error scales as generalised binary splitting algorithm thumb 300px an illustration of generalised binary splitting algorithm where there are 8 defectives and 135 total items here and first test gives a negative result so every item is declared non defective hence there are 119 remaining items so this second group gives a positive result so a binary search is used to find a defective once that is done whole process is repeated calculating a new using only those items whose defectiveness has not been determined generalised binary splitting algorithm is an essentially optimal adaptive group testing algorithm that finds or fewer defectives among items as follows if test items individually otherwise set and test a group of size if outcome is negative every item in group is declared to be non defective set and go to step 1 otherwise use a binary search to identify one defective and an unspecified number called of non defective items set and go to step 1 generalised binary splitting algorithm requires no more than tests where for large it can be shown that which compares favorably to tests required for li s stage algorithm in fact generalised binary splitting algorithm is close to optimal in following sense when it can be shown that where is information lower bound non adaptive algorithms non adaptive group testing algorithms tend to assume that number of defectives or at least a good upper bound on them is known this quantity is denoted in this section if no bounds are known there are non adaptive algorithms with low query complexity that can help estimate combinatorial orthogonal matching pursuit comp thumb an illustration of comp algorithm comp identifies item a as being defective and item b as being non defective however it incorrectly labels c as a defective since it is hidden by defective items in every test in which it appears combinatorial orthogonal matching pursuit or comp is a simple non adaptive group testing algorithm that forms basis for more complicated algorithms that follow in this section first each entry of testing matrix is chosen i i d to be with probability and otherwise decoding step proceeds column wise i e by item if every test in which an item appears is positive then item is declared defective otherwise item is assumed to be non defective or equivalently if an item appears in any test whose outcome is negative item is declared non defective otherwise item is assumed to be defective an important property of this algorithm is that it never creates false negatives though a false positive occurs when all locations with ones in j th column of corresponding to a non defective item j are hidden by ones of other columns corresponding to defective items comp algorithm requires no more than tests to have an error probability less than or equal to this is within a constant factor of lower bound for average probability of error above in noisy case one relaxes requirement in original comp algorithm that set of locations of ones in any column of corresponding to a positive item be entirely contained in set of locations of ones in result vector instead one allows for a certain number of mismatches this number of mismatches depends on both number of ones in each column and also noise parameter this noisy comp algorithm requires no more than tests to achieve an error probability at most definite defectives dd definite defectives method dd is an extension of comp algorithm that attempts to remove any false positives performance guarantees for dd have been shown to strictly exceed those of comp decoding step uses a useful property of comp algorithm that every item that comp declares non defective is certainly non defective that is there are no false negatives it proceeds as follows first comp algorithm is run and any non defectives that it detects are removed all remaining items are now possibly defective next algorithm looks at all positive tests if an item appears as only possible defective in a test then it must be defective so algorithm declares it to be defective all other items are assumed to be non defective justification for this last step comes from assumption that number of defectives is much smaller than total number of items note that steps 1 and 2 never make a mistake so algorithm can only make a mistake if it declares a defective item to be non defective thus dd algorithm can only create false negatives sequential comp scomp scomp sequential comp is an algorithm that makes use of fact that dd makes no mistakes until last step where it is assumed that remaining items are non defective let set of declared defectives be a positive test is called explained by if it contains at least one item in key observation with scomp is that set of defectives found by dd may not explain every positive test and that every unexplained test must contain a hidden defective algorithm proceeds as follows carry out steps 1 and 2 of dd algorithm to obtain an initial estimate for set of defectives if explains every positive test terminate algorithm is final estimate for set of defectives if there are any unexplained tests find possible defective that appears in largest number of unexplained tests and declare it to be defective that is add it to set go to step 2 in simulations scomp has been shown to perform close to optimally example applications generality of theory of group testing lends it to many diverse applications including clone screening locating electrical shorts high speed computer networks medical examination quantity searching statistics machine learning dna sequencing cryptography and data forensics this section provides a brief overview of a small selection of these applications multiaccess channels thumb an illustration of a multiaccess channel showing a successful message and a message collision a multiaccess channel is a communication channel that connects many users at once every user can listen and transmit on channel but if more than one user transmits at same time signals collide and are reduced to unintelligible noise multiaccess channels are important for various real world applications notably wireless computer networks and phone networks b s 2001 randomized communication in radio networks in p m rajasekaran s j j d p eds handbook of randomized computing vol i p 401 456 kluwer academic publishers dordrecht a prominent problem with multiaccess channels is how to assign transmission times to users so that their messages do not collide a simple method is to give each user their own time slot in which to transmit requiring slots this is called time division multiplexing or tdm however this is very inefficient since it will assign transmission slots to users that may not have a message and it is usually assumed that only a few users will want to transmit at any given time otherwise a multiaccess channel is not practical in first place in context of group testing this problem is usually tackled by dividing time into epochs in following way a user is called active if they have a message at start of an epoch if a message is generated during an epoch user only becomes active at start of next one an epoch ends when every active user has successfully transmitted their message problem is then to find all active users in a given epoch and schedule a time for them to transmit if they have not already done so successfully here a test on a set of users corresponds to those users attempting a transmission results of test are number of users that attempted to transmit and corresponding respectively to no active users exactly one active user message successful or more than one active user message collision therefore using an adaptive group testing algorithm with outcomes it can be determined which users wish to transmit in epoch then any user that has not yet made a successful transmission can now be assigned a slot to transmit without wastefully assigning times to inactive users machine learning and compressed sensing machine learning is a field of computer science that has many software applications such as dna classification fraud detection and targeted advertising one of main subfields of machine learning is learning by examples problem where task is to approximate some unknown function when given its value at a number of specific points as outlined in this section this function learning problem can be tackled with a group testing approach in a simple version of problem there is some unknown function where and using logical arithmetic addition is logical or and multiplication is logical and here is sparse which means that at most of its entries are aim is to construct an approximation to using point evaluations where is as small as possible exactly recovering corresponds to zero error algorithms whereas is approximated by algorithms that have a non zero probability of error in this problem recovering is equivalent to finding moreover if and only if there is some index where thus this problem is analogous to a group testing problem with defectives and total items entries of are items which are defective if they are specifies a test and a test is positive if and only if in reality one will often be interested in functions that are more complicated such as again where compressed sensing which is closely related to group testing can be used to solve this problem in compressed sensing goal is to reconstruct a signal by taking a number of measurements these measurements are modelled as taking dot product of with a chosen vector aim is to use a small number of measurements though this is typically not possible unless something is assumed about signal one such assumption which is a c m a strauss m j october 2008 group testing and sparse signal recovery 42nd asilomar conference on signals systems and computers 1059 1063 institute of electrical and electronics engineers is that only a small number of entries of are significant meaning that they have a large magnitude since measurements are dot products of equation holds where is a matrix that describes set of measurements that have been chosen and is set of measurement results this construction shows that compressed sensing is a kind of continuous group testing primary difficulty in compressed sensing is identifying which entries are significant once that is done there are a variety of methods to estimate actual values of entries this task of identification can be approached with a simple application of group testing here a group test produces a complex number sum of entries that are tested outcome of a test is called positive if it produces a complex number with a large magnitude which given assumption that significant entries are sparse indicates that at least one significant entry is contained in test there are explicit deterministic constructions for this type of combinatorial search algorithm requiring measurements however as with group testing these are sub optimal and random constructions such as comp can often recover sub linearly in data forensics data forensics is a field dedicated to finding methods for compiling digital evidence of a crime such crimes typically involve an adversary modifying data documents or databases of a victim with examples including altering of tax records a virus hiding its presence or an identity thief modifying personal data a common tool in data forensics is one way cryptographic hash this is a function that takes data and through a difficult to reverse procedure produces a unique number called a hash hashes which are often much shorter than data allow us to check if data has been changed without having to wastefully store complete copies of information hash for current data can be compared with a past hash to determine if any changes have occurred an unfortunate property of this method is that although it is easy to tell if data has been modified there is no way of determining how that is it is impossible to recover which part of data has changed one way to get around this limitation is to store more hashes now of subsets of data structure to narrow down where attack has occurred however to find exact location of attack with a naive approach a hash would need to be stored for every datum in structure which would defeat point of hashes in first place one may as well store a regular copy of data group testing can be used to dramatically reduce number of hashes that need to be stored a test becomes a comparison between stored and current hashes which is positive when there is a mismatch this indicates that at least one edited datum which is taken as defectiveness in this model is contained in group that generated current hash in fact amount of hashes needed is so low that they along with testing matrix they refer to can even be stored within organisational structure of data itself this means that as far as memory is concerned test can be performed for free this is true with exception of a master key password that is used to secretly determine hashing function notes references citations general references atri rudra s course on error correcting codes combinatorics algorithms and applications spring 2007 lectures 7 atri rudra s course on error correcting codes combinatorics algorithms and applications spring 2010 lectures 10 11 28 29 du d hwang f 2006 pooling designs and nonadaptive group testing boston twayne publishers ely porat amir rothschild explicit non adaptive combinatorial group testing schemes 1 2008 748 759 see also balance puzzle category combinatorics category design of experiments